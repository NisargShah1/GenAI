{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b1cd05-e52f-40e1-998c-9f6d3e62d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (4.1.0)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (2.5.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from bert-score) (23.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: click in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from requests->bert-score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from requests->bert-score) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py): started\n",
      "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=9e77d988301f01010db9d990d413144c300d01e9c7da7fac242bd1a87cfaacae\n",
      "  Stored in directory: c:\\users\\nisharg\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score, bert-score\n",
      "Successfully installed absl-py-2.3.0 bert-score-0.3.13 rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers rouge-score bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3aedbab-7c6b-494a-b5f5-32c0592584fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266d83dc74304adf9e1fcc251cabc80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nisharg\\GENAI\\annaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nisharg\\.cache\\huggingface\\hub\\models--roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81340bac8534a8da4c6a28bb5a6f5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a829d11ad8f041dc8a1d0ba744631a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae59d9ff42fa4afb899ec65566b9efa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1353d889bb544fd9b2263ae6db785ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53f1636f9d640f28e005bd2c76eb71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bert_score_f1': 0.9299,\n",
      "  'cosine_similarity': 0.7858,\n",
      "  'ground_truth': 'World War I was caused by a combination of nationalism, '\n",
      "                  'militarism, alliances, and imperial rivalries. The '\n",
      "                  'immediate trigger was the assassination of Archduke Franz '\n",
      "                  'Ferdinand in 1914.',\n",
      "  'prediction': 'The war began due to rising nationalism, a buildup of '\n",
      "                'military power, and a complex web of alliances. The '\n",
      "                'assassination of Archduke Franz Ferdinand served as the spark '\n",
      "                'for the conflict.',\n",
      "  'question': 'Explain the causes of World War I.',\n",
      "  'rouge1': 0.4483,\n",
      "  'rouge2': 0.1786,\n",
      "  'rougeL': 0.3448},\n",
      " {'bert_score_f1': 0.9249,\n",
      "  'cosine_similarity': 0.8387,\n",
      "  'ground_truth': 'Exercise improves cardiovascular health, boosts mood, helps '\n",
      "                  'with weight management, strengthens muscles and bones, and '\n",
      "                  'can reduce the risk of chronic diseases like diabetes and '\n",
      "                  'hypertension.',\n",
      "  'prediction': 'Regular physical activity can improve heart health, regulate '\n",
      "                'body weight, enhance mental well-being, and lower the chances '\n",
      "                'of conditions like diabetes and high blood pressure.',\n",
      "  'question': 'What are the benefits of exercise?',\n",
      "  'rouge1': 0.3846,\n",
      "  'rouge2': 0.08,\n",
      "  'rougeL': 0.3462}]\n",
      "\n",
      "Average Metrics:\n",
      "Cosine Similarity: 0.8123\n",
      "ROUGE-1: 0.4164\n",
      "ROUGE-2: 0.1293\n",
      "ROUGE-L: 0.3455\n",
      "BERTScore F1: 0.9274\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "import numpy as np\n",
    "\n",
    "# Sample long-answer test set\n",
    "test_data = [\n",
    "    {\n",
    "        \"question\": \"Explain the causes of World War I.\",\n",
    "        \"ground_truth\": \"World War I was caused by a combination of nationalism, militarism, alliances, and imperial rivalries. The immediate trigger was the assassination of Archduke Franz Ferdinand in 1914.\",\n",
    "        \"prediction\": \"The war began due to rising nationalism, a buildup of military power, and a complex web of alliances. The assassination of Archduke Franz Ferdinand served as the spark for the conflict.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the benefits of exercise?\",\n",
    "        \"ground_truth\": \"Exercise improves cardiovascular health, boosts mood, helps with weight management, strengthens muscles and bones, and can reduce the risk of chronic diseases like diabetes and hypertension.\",\n",
    "        \"prediction\": \"Regular physical activity can improve heart health, regulate body weight, enhance mental well-being, and lower the chances of conditions like diabetes and high blood pressure.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load models\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for item in test_data:\n",
    "    pred = item[\"prediction\"]\n",
    "    gt = item[\"ground_truth\"]\n",
    "\n",
    "    # Cosine similarity\n",
    "    emb_pred = bert_model.encode(pred, convert_to_tensor=True)\n",
    "    emb_gt = bert_model.encode(gt, convert_to_tensor=True)\n",
    "    cosine_sim = util.pytorch_cos_sim(emb_pred, emb_gt).item()\n",
    "\n",
    "    # ROUGE\n",
    "    r_scores = rouge.score(gt, pred)\n",
    "    rouge1 = r_scores[\"rouge1\"].fmeasure\n",
    "    rouge2 = r_scores[\"rouge2\"].fmeasure\n",
    "    rougel = r_scores[\"rougeL\"].fmeasure\n",
    "\n",
    "    results.append({\n",
    "        \"question\": item[\"question\"],\n",
    "        \"prediction\": pred,\n",
    "        \"ground_truth\": gt,\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        \"rouge1\": round(rouge1, 4),\n",
    "        \"rouge2\": round(rouge2, 4),\n",
    "        \"rougeL\": round(rougel, 4)\n",
    "    })\n",
    "\n",
    "# BERTScore (evaluate all at once)\n",
    "preds = [r[\"prediction\"] for r in results]\n",
    "gts = [r[\"ground_truth\"] for r in results]\n",
    "P, R, F1 = score(preds, gts, lang='en', verbose=False)\n",
    "\n",
    "for i, f in enumerate(F1):\n",
    "    results[i][\"bert_score_f1\"] = round(f.item(), 4)\n",
    "\n",
    "# Print\n",
    "from pprint import pprint\n",
    "pprint(results)\n",
    "\n",
    "# Averages\n",
    "avg_cosine = np.mean([r[\"cosine_similarity\"] for r in results])\n",
    "avg_rouge1 = np.mean([r[\"rouge1\"] for r in results])\n",
    "avg_rouge2 = np.mean([r[\"rouge2\"] for r in results])\n",
    "avg_rougel = np.mean([r[\"rougeL\"] for r in results])\n",
    "avg_bert = np.mean([r[\"bert_score_f1\"] for r in results])\n",
    "\n",
    "print(\"\\nAverage Metrics:\")\n",
    "print(f\"Cosine Similarity: {avg_cosine:.4f}\")\n",
    "print(f\"ROUGE-1: {avg_rouge1:.4f}\")\n",
    "print(f\"ROUGE-2: {avg_rouge2:.4f}\")\n",
    "print(f\"ROUGE-L: {avg_rougel:.4f}\")\n",
    "print(f\"BERTScore F1: {avg_bert:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9894f-7bc0-4e89-8dad-535d27153f02",
   "metadata": {},
   "source": [
    "ðŸ” ROUGE Scores Breakdown:\n",
    "Metric\tValue\tMeaning\n",
    "rouge1\t0.3846\t38.5% unigram (word) overlap between prediction and reference.\n",
    "rouge2\t0.08\t8% bigram (2-word sequence) overlap. This is much harder to match, especially for paraphrased answers.\n",
    "rougeL\t0.3462\tMeasures Longest Common Subsequence (LCS). 34.6% of the word sequence matches in order.\n",
    "\n",
    "ðŸ“Œ Interpretation\n",
    "ROUGE-1 is relatively moderate, showing decent word overlap â€” words like \"health\", \"weight\", \"diabetes\", etc., occur in both.\n",
    "\n",
    "ROUGE-2 is low â€” because the prediction paraphrased the ground truth. Matching exact 2-word sequences like â€œcardiovascular healthâ€ or â€œchronic diseasesâ€ is harder.\n",
    "\n",
    "ROUGE-L is higher than ROUGE-2 because it rewards ordered subsequences even if theyâ€™re not exact n-gram matches.\n",
    "\n",
    "ðŸ†š Compared with Semantic Metrics\n",
    "Metric\tValue\tMeaning\n",
    "bert_score_f1\t0.9249\tShows strong semantic similarity using BERT embeddings (close to 1 = very similar meaning).\n",
    "cosine_similarity\t0.8387\tVector similarity â€” also supports that prediction and reference are semantically close.\n",
    "\n",
    "ðŸ”Ž These confirm: even if ROUGE scores are lower (due to paraphrasing), semantically the answer is very good.\n",
    "\n",
    "âœ… When to Use ROUGE vs. Semantic Metrics\n",
    "Use Case\t            Prefer ROUGE\tPrefer BERT / Cosine\n",
    "Exact phrasing matters\t    âœ…\t         âŒ\n",
    "Meaning over wording\t    âŒ\t         âœ…\n",
    "Short answers (e.g. QA) \tâœ…\t         âœ…\n",
    "Long, paraphrased responses\tâŒ\t         âœ…\n",
    "Summarization\t            âœ…         \t âœ… (BERTScore recommended too)\n",
    "\n",
    "ðŸ” Conclusion\n",
    "ROUGE-1 = 0.38 â†’ fair word overlap.\n",
    "\n",
    "ROUGE-2 = 0.08 â†’ low phrase overlap due to paraphrasing.\n",
    "\n",
    "ROUGE-L = 0.34 â†’ good overall sequence similarity.\n",
    "\n",
    "BERTScore (0.92) and cosine (0.83) show that the prediction is semantically correct and fluent, even though it uses different words.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
