{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b1cd05-e52f-40e1-998c-9f6d3e62d62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (4.1.0)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (4.47.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (2.5.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (0.27.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sentence-transformers) (4.11.0)\n",
      "Collecting absl-py (from rouge-score)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: pandas>=1.0.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: requests in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from bert-score) (3.9.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from bert-score) (23.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from pandas>=1.0.1->bert-score) (2023.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from matplotlib->bert-score) (3.1.2)\n",
      "Requirement already satisfied: click in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from nltk->rouge-score) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from nltk->rouge-score) (1.4.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from requests->bert-score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from requests->bert-score) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from requests->bert-score) (2024.8.30)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nisharg\\genai\\annaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py): started\n",
      "  Building wheel for rouge-score (setup.py): finished with status 'done'\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24972 sha256=9e77d988301f01010db9d990d413144c300d01e9c7da7fac242bd1a87cfaacae\n",
      "  Stored in directory: c:\\users\\nisharg\\appdata\\local\\pip\\cache\\wheels\\85\\9d\\af\\01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: absl-py, rouge-score, bert-score\n",
      "Successfully installed absl-py-2.3.0 bert-score-0.3.13 rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers rouge-score bert-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3aedbab-7c6b-494a-b5f5-32c0592584fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266d83dc74304adf9e1fcc251cabc80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nisharg\\GENAI\\annaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nisharg\\.cache\\huggingface\\hub\\models--roberta-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81340bac8534a8da4c6a28bb5a6f5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a829d11ad8f041dc8a1d0ba744631a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae59d9ff42fa4afb899ec65566b9efa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1353d889bb544fd9b2263ae6db785ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53f1636f9d640f28e005bd2c76eb71c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bert_score_f1': 0.9299,\n",
      "  'cosine_similarity': 0.7858,\n",
      "  'ground_truth': 'World War I was caused by a combination of nationalism, '\n",
      "                  'militarism, alliances, and imperial rivalries. The '\n",
      "                  'immediate trigger was the assassination of Archduke Franz '\n",
      "                  'Ferdinand in 1914.',\n",
      "  'prediction': 'The war began due to rising nationalism, a buildup of '\n",
      "                'military power, and a complex web of alliances. The '\n",
      "                'assassination of Archduke Franz Ferdinand served as the spark '\n",
      "                'for the conflict.',\n",
      "  'question': 'Explain the causes of World War I.',\n",
      "  'rouge1': 0.4483,\n",
      "  'rouge2': 0.1786,\n",
      "  'rougeL': 0.3448},\n",
      " {'bert_score_f1': 0.9249,\n",
      "  'cosine_similarity': 0.8387,\n",
      "  'ground_truth': 'Exercise improves cardiovascular health, boosts mood, helps '\n",
      "                  'with weight management, strengthens muscles and bones, and '\n",
      "                  'can reduce the risk of chronic diseases like diabetes and '\n",
      "                  'hypertension.',\n",
      "  'prediction': 'Regular physical activity can improve heart health, regulate '\n",
      "                'body weight, enhance mental well-being, and lower the chances '\n",
      "                'of conditions like diabetes and high blood pressure.',\n",
      "  'question': 'What are the benefits of exercise?',\n",
      "  'rouge1': 0.3846,\n",
      "  'rouge2': 0.08,\n",
      "  'rougeL': 0.3462}]\n",
      "\n",
      "Average Metrics:\n",
      "Cosine Similarity: 0.8123\n",
      "ROUGE-1: 0.4164\n",
      "ROUGE-2: 0.1293\n",
      "ROUGE-L: 0.3455\n",
      "BERTScore F1: 0.9274\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "import numpy as np\n",
    "\n",
    "# Sample long-answer test set\n",
    "test_data = [\n",
    "    {\n",
    "        \"question\": \"Explain the causes of World War I.\",\n",
    "        \"ground_truth\": \"World War I was caused by a combination of nationalism, militarism, alliances, and imperial rivalries. The immediate trigger was the assassination of Archduke Franz Ferdinand in 1914.\",\n",
    "        \"prediction\": \"The war began due to rising nationalism, a buildup of military power, and a complex web of alliances. The assassination of Archduke Franz Ferdinand served as the spark for the conflict.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the benefits of exercise?\",\n",
    "        \"ground_truth\": \"Exercise improves cardiovascular health, boosts mood, helps with weight management, strengthens muscles and bones, and can reduce the risk of chronic diseases like diabetes and hypertension.\",\n",
    "        \"prediction\": \"Regular physical activity can improve heart health, regulate body weight, enhance mental well-being, and lower the chances of conditions like diabetes and high blood pressure.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Load models\n",
    "bert_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "results = []\n",
    "\n",
    "for item in test_data:\n",
    "    pred = item[\"prediction\"]\n",
    "    gt = item[\"ground_truth\"]\n",
    "\n",
    "    # Cosine similarity\n",
    "    emb_pred = bert_model.encode(pred, convert_to_tensor=True)\n",
    "    emb_gt = bert_model.encode(gt, convert_to_tensor=True)\n",
    "    cosine_sim = util.pytorch_cos_sim(emb_pred, emb_gt).item()\n",
    "\n",
    "    # ROUGE\n",
    "    r_scores = rouge.score(gt, pred)\n",
    "    rouge1 = r_scores[\"rouge1\"].fmeasure\n",
    "    rouge2 = r_scores[\"rouge2\"].fmeasure\n",
    "    rougel = r_scores[\"rougeL\"].fmeasure\n",
    "\n",
    "    results.append({\n",
    "        \"question\": item[\"question\"],\n",
    "        \"prediction\": pred,\n",
    "        \"ground_truth\": gt,\n",
    "        \"cosine_similarity\": round(cosine_sim, 4),\n",
    "        \"rouge1\": round(rouge1, 4),\n",
    "        \"rouge2\": round(rouge2, 4),\n",
    "        \"rougeL\": round(rougel, 4)\n",
    "    })\n",
    "\n",
    "# BERTScore (evaluate all at once)\n",
    "preds = [r[\"prediction\"] for r in results]\n",
    "gts = [r[\"ground_truth\"] for r in results]\n",
    "P, R, F1 = score(preds, gts, lang='en', verbose=False)\n",
    "\n",
    "for i, f in enumerate(F1):\n",
    "    results[i][\"bert_score_f1\"] = round(f.item(), 4)\n",
    "\n",
    "# Print\n",
    "from pprint import pprint\n",
    "pprint(results)\n",
    "\n",
    "# Averages\n",
    "avg_cosine = np.mean([r[\"cosine_similarity\"] for r in results])\n",
    "avg_rouge1 = np.mean([r[\"rouge1\"] for r in results])\n",
    "avg_rouge2 = np.mean([r[\"rouge2\"] for r in results])\n",
    "avg_rougel = np.mean([r[\"rougeL\"] for r in results])\n",
    "avg_bert = np.mean([r[\"bert_score_f1\"] for r in results])\n",
    "\n",
    "print(\"\\nAverage Metrics:\")\n",
    "print(f\"Cosine Similarity: {avg_cosine:.4f}\")\n",
    "print(f\"ROUGE-1: {avg_rouge1:.4f}\")\n",
    "print(f\"ROUGE-2: {avg_rouge2:.4f}\")\n",
    "print(f\"ROUGE-L: {avg_rougel:.4f}\")\n",
    "print(f\"BERTScore F1: {avg_bert:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9894f-7bc0-4e89-8dad-535d27153f02",
   "metadata": {},
   "source": [
    "🔍 ROUGE Scores Breakdown:\n",
    "Metric\tValue\tMeaning\n",
    "rouge1\t0.3846\t38.5% unigram (word) overlap between prediction and reference.\n",
    "rouge2\t0.08\t8% bigram (2-word sequence) overlap. This is much harder to match, especially for paraphrased answers.\n",
    "rougeL\t0.3462\tMeasures Longest Common Subsequence (LCS). 34.6% of the word sequence matches in order.\n",
    "\n",
    "📌 Interpretation\n",
    "ROUGE-1 is relatively moderate, showing decent word overlap — words like \"health\", \"weight\", \"diabetes\", etc., occur in both.\n",
    "\n",
    "ROUGE-2 is low — because the prediction paraphrased the ground truth. Matching exact 2-word sequences like “cardiovascular health” or “chronic diseases” is harder.\n",
    "\n",
    "ROUGE-L is higher than ROUGE-2 because it rewards ordered subsequences even if they’re not exact n-gram matches.\n",
    "\n",
    "🆚 Compared with Semantic Metrics\n",
    "Metric\tValue\tMeaning\n",
    "bert_score_f1\t0.9249\tShows strong semantic similarity using BERT embeddings (close to 1 = very similar meaning).\n",
    "cosine_similarity\t0.8387\tVector similarity — also supports that prediction and reference are semantically close.\n",
    "\n",
    "🔎 These confirm: even if ROUGE scores are lower (due to paraphrasing), semantically the answer is very good.\n",
    "\n",
    "✅ When to Use ROUGE vs. Semantic Metrics\n",
    "Use Case\t            Prefer ROUGE\tPrefer BERT / Cosine\n",
    "Exact phrasing matters\t    ✅\t         ❌\n",
    "Meaning over wording\t    ❌\t         ✅\n",
    "Short answers (e.g. QA) \t✅\t         ✅\n",
    "Long, paraphrased responses\t❌\t         ✅\n",
    "Summarization\t            ✅         \t ✅ (BERTScore recommended too)\n",
    "\n",
    "🔁 Conclusion\n",
    "ROUGE-1 = 0.38 → fair word overlap.\n",
    "\n",
    "ROUGE-2 = 0.08 → low phrase overlap due to paraphrasing.\n",
    "\n",
    "ROUGE-L = 0.34 → good overall sequence similarity.\n",
    "\n",
    "BERTScore (0.92) and cosine (0.83) show that the prediction is semantically correct and fluent, even though it uses different words.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
